{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:44:07.456600500Z",
     "start_time": "2024-05-06T22:44:05.492552300Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import include.Model_and_Methods as mm\n",
    "import os\n",
    "from os.path import join\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda:0\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "torch.set_default_device(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:44:08.315010900Z",
     "start_time": "2024-05-06T22:44:08.288293500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def load_result_dicts(directory, strategy_name, num_seeds, num_total_expansions, eps, lr, grad_clip,\n",
    "                      initial_network_id):\n",
    "    result_dict_list = []\n",
    "    start_seed = 1\n",
    "    for seed in range(start_seed, num_seeds + start_seed):\n",
    "        if num_total_expansions > 0:\n",
    "            result_dict_list.append(torch.load(\n",
    "                directory + \"/\" + strategy_name + f\"_result_seed_{seed}_expansions_{num_total_expansions}_eps_{eps}_lr_{lr}_grad_clip_{grad_clip}_initial_network_{initial_network_id}.pt\"))\n",
    "        else:\n",
    "            added_name = \"_with_loss_convergence_termination\" # remove this from the path name below to obtain the baseline model trained for a fixed number of epochs(=50) \n",
    "            result_dict_list.append(torch.load(\n",
    "                directory + \"/\" + strategy_name + f\"_result_seed_{seed}_lr_{lr}_grad_clip_{grad_clip}.pt\"))  #{added_name}\n",
    "    return result_dict_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:44:08.825538Z",
     "start_time": "2024-05-06T22:44:08.823877200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_result_list_end_epoch(list, training_data_size=60000, log_interval=100,\n",
    "                              batch_size=100):  # does not hold for \"index_before_expand\"\n",
    "    stepsize = int(training_data_size / (log_interval * batch_size))\n",
    "    return list[stepsize - 1::stepsize]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:44:09.403187Z",
     "start_time": "2024-05-06T22:44:09.401444900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# def convert_list_to_numpy(list, elements_are_tensor):\n",
    "#     if elements_are_tensor:\n",
    "#         list = [list[i].item() for i in range(len(list))]\n",
    "#     return np.array(list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:44:09.813542Z",
     "start_time": "2024-05-06T22:44:09.809941400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def tolerant_mean(arrs):\n",
    "    lens = [len(i) for i in arrs]\n",
    "    arr = np.ma.empty((np.max(lens), len(arrs)))\n",
    "    arr.mask = True  # represents missing value\n",
    "    for idx, l in enumerate(arrs):\n",
    "        arr[:len(l), idx] = l\n",
    "    return arr.mean(axis=-1), arr.std(axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:44:10.266781400Z",
     "start_time": "2024-05-06T22:44:10.253767800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def tensor_mean(\n",
    "        tensor_list):  # can not handle missing values, suited for multi-dimensional arrays (matrices, tensors, etc)\n",
    "    mean_tensor = np.zeros_like(tensor_list[0])\n",
    "    for i in range(len(tensor_list)):\n",
    "        mean_tensor += tensor_list[i]\n",
    "    mean_tensor = mean_tensor / len(tensor_list)\n",
    "    return mean_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:44:11.065763400Z",
     "start_time": "2024-05-06T22:44:11.063742700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_params_layers_expansions(mask_dict_list):  # can not handle missing values\n",
    "    num_expansions = len(mask_dict_list)\n",
    "    num_layers = len(mask_dict_list[0][\"weights\"])\n",
    "\n",
    "    accumulated_params_added_to_layers = [[(torch.count_nonzero(\n",
    "        mask_dict_list[expansion][\"weights\"][layer]).item() + torch.count_nonzero(\n",
    "        mask_dict_list[expansion][\"biases\"][layer]).item()) for layer in range(num_layers)] for expansion in\n",
    "                                          range(num_expansions)]  # accumulated\n",
    "    accumulated_params_added_to_layers.append(\n",
    "        [(torch.numel(mask_dict_list[0][\"weights\"][layer]) + torch.numel(mask_dict_list[0][\"biases\"][layer])) for layer\n",
    "         in range(num_layers)])\n",
    "\n",
    "    params_added_to_layers = [[(torch.count_nonzero(\n",
    "        mask_dict_list[expansion][\"weights\"][layer]).item() + torch.count_nonzero(\n",
    "        mask_dict_list[expansion][\"biases\"][layer]).item()) for layer in range(num_layers)] for expansion in\n",
    "                              range(num_expansions)]  # non accumulated\n",
    "    params_added_to_layers.append(\n",
    "        [(torch.numel(mask_dict_list[0][\"weights\"][layer]) + torch.numel(mask_dict_list[0][\"biases\"][layer])) for layer\n",
    "         in range(num_layers)])\n",
    "\n",
    "    for e in range(num_expansions + 1):\n",
    "        for l in range(num_layers):\n",
    "            if e != 0:\n",
    "                params_added_to_layers[e][l] -= accumulated_params_added_to_layers[e - 1][l]\n",
    "\n",
    "    return params_added_to_layers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:44:11.631171200Z",
     "start_time": "2024-05-06T22:44:11.629662400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def plot_with_std_expansions_baseline(ax, x, y, y_std, label, epoch_before_expand,\n",
    "                                      mean_baseline_acc, num_params_mean_arr, num_total_params, flag_only_baseline_peak,\n",
    "                                      acc_means_random_baseline):  # for loss and accuracy\n",
    "    ax.plot(x, y, color=\"blue\", label=label)\n",
    "    ax.plot(np.arange(1, acc_means_random_baseline.size + 1), acc_means_random_baseline, color=\"orange\",\n",
    "            label=\"random strategy\")\n",
    "    ax.fill_between(x, y + y_std, y - y_std, facecolor='blue', alpha=0.5)\n",
    "    # ax.vlines(x=epoch_before_expand, ymin=ax.get_ylim()[0], ymax=ax.get_ylim()[1], colors=\"green\",\n",
    "    #           linestyles=\"dashed\", label=\"Expansion\", alpha=0.3)\n",
    "    # print(epoch_before_expand)\n",
    "    relative_num_params_at_expansion_epoch = [100 * num_params_mean_arr[int(i)] / num_total_params for i in\n",
    "                                              epoch_before_expand]  # epoch after expansion  \n",
    "    ax.bar(epoch_before_expand, relative_num_params_at_expansion_epoch, color=\"green\", alpha=0.5)\n",
    "    if flag_only_baseline_peak:\n",
    "        ax.hlines(y=np.max(mean_baseline_acc), xmin=ax.get_xlim()[0], xmax=ax.get_xlim()[1], colors=\"red\",\n",
    "                  linestyles=\"dashed\",\n",
    "                  label=\"Baseline Peak\", alpha=0.3)\n",
    "    else:\n",
    "        ax.plot(np.arange(1, len(mean_baseline_acc) + 1), mean_baseline_acc, color=\"red\", label=\"baseline\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:44:12.902444700Z",
     "start_time": "2024-05-06T22:44:12.889923400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "num_expansions = 5 #TODO\n",
    "eps = 0.01\n",
    "grad_clip = 100\n",
    "lr = 0.001\n",
    "initial_network_id = 2\n",
    "num_seeds = 5\n",
    "fashion_mnist_name = \"Fashion_MNIST\"\n",
    "mnist_name = \"MNIST\"\n",
    "dataset_name = fashion_mnist_name\n",
    "strategies_result_dict = dict()\n",
    "strategies_result_dict[\"random_edges\"] = load_result_dicts(\"../results/strategy1_random/edges\" + \"/\" + dataset_name,\n",
    "                                                           \"random_edges\", num_seeds, num_expansions, eps, lr,\n",
    "                                                           grad_clip, initial_network_id)\n",
    "strategies_result_dict[\"random_neurons\"] = load_result_dicts(\"../results/strategy1_random/neurons\" + \"/\" + dataset_name,\n",
    "                                                             \"random_neurons\", num_seeds, num_expansions,\n",
    "                                                             eps, lr, grad_clip, initial_network_id)\n",
    "strategies_result_dict[\"constant_edges\"] = load_result_dicts(\"../results/strategy2_constant/edges\" + \"/\" + dataset_name,\n",
    "                                                             \"constant_edges\", num_seeds, num_expansions,\n",
    "                                                             eps, lr, grad_clip, initial_network_id)\n",
    "strategies_result_dict[\"constant_neurons\"] = load_result_dicts(\n",
    "    \"../results/strategy2_constant/neurons\" + \"/\" + dataset_name, \"constant_neurons\", num_seeds,\n",
    "    num_expansions, eps, lr, grad_clip, initial_network_id)\n",
    "strategies_result_dict[\"regularized_edges\"] = load_result_dicts(\n",
    "    \"../results/strategy3_regularized/edges\" + \"/\" + dataset_name, \"regularized_edges\",\n",
    "    num_seeds, num_expansions,\n",
    "    eps, lr, grad_clip, initial_network_id)\n",
    "strategies_result_dict[\"regularized_neurons\"] = load_result_dicts(\n",
    "    \"../results/strategy3_regularized/neurons\" + \"/\" + dataset_name,\n",
    "    \"regularized_neurons\", num_seeds,\n",
    "    num_expansions, eps, lr, grad_clip, initial_network_id)\n",
    "strategies_result_dict[\"initial_edges\"] = load_result_dicts(\"../results/strategy4_initial/edges\" + \"/\" + dataset_name,\n",
    "                                                            \"initial_edges\", num_seeds, num_expansions, eps, lr,\n",
    "                                                            grad_clip, initial_network_id)\n",
    "strategies_result_dict[\"initial_neurons\"] = load_result_dicts(\n",
    "    \"../results/strategy4_initial/neurons\" + \"/\" + dataset_name, \"initial_neurons\", num_seeds, num_expansions, eps, lr,\n",
    "    grad_clip, initial_network_id)\n",
    "\n",
    "strategies_result_dict[\"warmstarted_edges\"] = load_result_dicts(\n",
    "    \"../results/strategy4_warmstarted/edges\" + \"/\" + dataset_name, \"warmstarted_edges\", num_seeds, num_expansions, eps,\n",
    "    lr, grad_clip, initial_network_id)\n",
    "strategies_result_dict[\"warmstarted_neurons\"] = load_result_dicts(\n",
    "    \"../results/strategy4_warmstarted/neurons\" + \"/\" + dataset_name, \"warmstarted_neurons\", num_seeds, num_expansions,\n",
    "    eps, lr, grad_clip, initial_network_id)\n",
    "\n",
    "strategies_result_dict[\"gradient_based_edges\"] = load_result_dicts(\n",
    "    \"../results/strategy5_gradient_based/edges\" + \"/\" + dataset_name, \"gradient_based_edges\", num_seeds, num_expansions,\n",
    "    eps, lr, grad_clip, initial_network_id)\n",
    "strategies_result_dict[\"gradient_based_neurons\"] = load_result_dicts(\n",
    "    \"../results/strategy5_gradient_based/neurons\" + \"/\" + dataset_name, \"gradient_based_neurons\", num_seeds,\n",
    "    num_expansions, eps, lr, grad_clip, initial_network_id)\n",
    "\n",
    "strategies_result_dict[\"layer_stat_edges\"] = load_result_dicts(\n",
    "    \"../results/strategy6_layer_stat/edges\" + \"/\" + dataset_name, \"layer_stat_edges\", num_seeds, num_expansions, eps,\n",
    "    lr, grad_clip, initial_network_id)\n",
    "strategies_result_dict[\"layer_stat_neurons\"] = load_result_dicts(\n",
    "    \"../results/strategy6_layer_stat/neurons\" + \"/\" + dataset_name, \"layer_stat_neurons\", num_seeds, num_expansions,\n",
    "    eps, lr, grad_clip, initial_network_id)\n",
    "\n",
    "# strategies_result_dict[\"splitting_neurons_eigenvectors_init\"] = load_result_dicts(\"../results/strategy5_splitting/neurons\" + \"/\" + dataset_name, \"splitting_neurons_eigenvectors_init\", num_seeds, num_expansions, eps)\n",
    "\n",
    "# result_dict_list_layer_statistics_edges = load_result_dicts(\"../results/strategy6_layer_statistics/edges\", \"layer_statistics_edges\", num_seeds, num_expansions, eps)\n",
    "# result_dict_list_layer_statistics_neurons = load_result_dicts(\"../results/strategy6_layer_statistics/neurons\", \"layer_statistics_neurons\", num_seeds, num_expansions, eps)\n",
    "\n",
    "strategies_result_dict[\"baseline\"] = load_result_dicts(\"../results/baseline\" + \"/\" + dataset_name, \"baseline\",\n",
    "                                                       num_seeds, 0, 0, lr, grad_clip, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:54:57.787098100Z",
     "start_time": "2024-05-06T22:54:55.841336900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "num_total_params = strategies_result_dict[\"random_edges\"][0][\"num_params\"][-1]\n",
    "\n",
    "# evaluating only one entry per epoch\n",
    "\n",
    "strategies_test_accuracy = dict()\n",
    "strategies_epoch_before_expand = dict()\n",
    "strategies_num_params = dict()\n",
    "strategies_num_params_layers_expansions = dict()\n",
    "\n",
    "for strategy in strategies_result_dict.keys():\n",
    "    strategies_test_accuracy[strategy] = []\n",
    "\n",
    "    if strategy != \"baseline\":\n",
    "        strategies_epoch_before_expand[strategy] = []\n",
    "        strategies_num_params[strategy] = []\n",
    "        strategies_num_params_layers_expansions[strategy] = []\n",
    "\n",
    "for seed in range(num_seeds):\n",
    "    for strategy in strategies_result_dict.keys():\n",
    "        strategies_test_accuracy[strategy].append(\n",
    "            np.array(get_result_list_end_epoch(strategies_result_dict[strategy][seed][\"test_accuracy\"])))\n",
    "        if strategy != \"baseline\":\n",
    "            strategies_epoch_before_expand[strategy].append(\n",
    "                (np.array(strategies_result_dict[strategy][seed][\"index_before_expand\"]) + 1) / 6)\n",
    "            strategies_num_params[strategy].append(\n",
    "                np.array(get_result_list_end_epoch(strategies_result_dict[strategy][seed][\"num_params\"])))\n",
    "            strategies_num_params_layers_expansions[strategy].append(\n",
    "                np.array(get_params_layers_expansions(strategies_result_dict[strategy][seed][\"masks\"])))\n",
    "\n",
    "acc_means = dict()\n",
    "acc_stds = dict()\n",
    "num_params_means = dict()\n",
    "expansion_indices_means = dict()\n",
    "expansion_indices_stds = dict()\n",
    "num_params_layers_expansions_means = dict()\n",
    "\n",
    "for strategy in strategies_result_dict.keys():\n",
    "    acc, std = tolerant_mean(strategies_test_accuracy[strategy])\n",
    "    acc_means[strategy] = acc\n",
    "    acc_stds[strategy] = std\n",
    "    if strategy != \"baseline\":\n",
    "        num_params_means[strategy] = tolerant_mean(strategies_num_params[strategy])[0]\n",
    "        expansion_indices_means[strategy], expansion_indices_stds[strategy] = tolerant_mean(strategies_epoch_before_expand[strategy])\n",
    "        num_params_layers_expansions_means[strategy] = tensor_mean(strategies_num_params_layers_expansions[strategy])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:54:59.375483600Z",
     "start_time": "2024-05-06T22:54:58.288761200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean training duration:  50.0\n",
      "mean accuracy:  86.08439999999999\n",
      "final accuracy:  86.244\n"
     ]
    }
   ],
   "source": [
    "print(\"mean training duration: \", np.mean([len(run) for run in strategies_test_accuracy[\"baseline\"]]))\n",
    "print(\"mean accuracy: \", np.mean(acc_means[\"baseline\"]))\n",
    "print(\"final accuracy: \", acc_means[\"baseline\"][-1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:54:59.941025500Z",
     "start_time": "2024-05-06T22:54:59.926629700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max epoch:  50\n"
     ]
    }
   ],
   "source": [
    "max_epoch = np.max([len(i) for i in acc_means.values()])\n",
    "print(\"max epoch: \", max_epoch)\n",
    "\n",
    "fig = plt.figure(figsize=(4 * 6.4, 4 * 4.8), layout=\"constrained\")  # 4 * 6.4, 3 * 4.8\n",
    "\n",
    "for i, strategy in enumerate(acc_means, start=1):  # iterates over keys which are the same for each result dict\n",
    "    if strategy != \"baseline\":\n",
    "        ax_i = fig.add_subplot(4, 4, i)  # 3, 4, i\n",
    "        ax_i.set_title(\"Accuracy \" + strategy)\n",
    "        ax_i.set_xlabel(\"Epoch\")\n",
    "        ax_i.set_ylabel(\"Accuracy (%)\")\n",
    "        ax_i.set_xlim((0, max_epoch))\n",
    "        ax_i.set_ylim((0, 100))\n",
    "        if \"edges\" in strategy:\n",
    "            plot_with_std_expansions_baseline(ax_i, np.arange(1, len(acc_means[strategy]) + 1), acc_means[strategy],\n",
    "                                              acc_stds[strategy], \"Test-Accuracy\",\n",
    "                                              expansion_indices_means[strategy], acc_means[\"baseline\"],\n",
    "                                              num_params_means[strategy], num_total_params, False,\n",
    "                                              acc_means[\"random_edges\"])\n",
    "        else:\n",
    "            plot_with_std_expansions_baseline(ax_i, np.arange(1, len(acc_means[strategy]) + 1), acc_means[strategy],\n",
    "                                              acc_stds[strategy], \"Test-Accuracy\",\n",
    "                                              expansion_indices_means[strategy], acc_means[\"baseline\"],\n",
    "                                              num_params_means[strategy], num_total_params, False,\n",
    "                                              acc_means[\"random_neurons\"])\n",
    "    plt.legend()\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    f'../plots/{dataset_name}/Accuracies_Many_Plots_seed_1_to_{num_seeds}_expansions_{num_expansions}_initial_network_{initial_network_id}.pdf',\n",
    "    bbox_inches=\"tight\")  # save the figure to file\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:49:58.424157900Z",
     "start_time": "2024-05-06T22:49:56.480807500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "colors = [\"blue\", \"green\", \"cyan\", \"purple\", \"orange\", \"brown\", \"magenta\", ]\n",
    "# alpha = 0.5\n",
    "fig = plt.figure(figsize=(6.4, 6.4), layout=\"constrained\")\n",
    "ax = fig.add_subplot(111)\n",
    "# ax.set_title(\"Test Accuracies der Strategien in Kantenperspektive\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Accuracy (%)\")\n",
    "ax.set_xlim((0, max_epoch))\n",
    "ax.set_ylim((0, 100))\n",
    "curr_strat_index = 0\n",
    "for i, strategy in enumerate(acc_means):  # iterates over keys which are the same for each result dict\n",
    "    if \"edges\" in strategy:\n",
    "        ax.plot(np.arange(1, len(acc_means[strategy]) + 1), acc_means[strategy], label=strategy,\n",
    "                color=colors[curr_strat_index], alpha=0.5)  #, alpha= alpha\n",
    "        curr_strat_index += 1\n",
    "        # if alpha == 0.5:\n",
    "        #     alpha -= 0.25\n",
    "        # else:\n",
    "        #     alpha += 0.25\n",
    "ax.plot(np.arange(1, len(acc_means[\"baseline\"]) + 1), acc_means[\"baseline\"], color=\"red\", label=\"baseline\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    f'../plots/{dataset_name}/Accuracies_Edges_One_Plot_seed_1_to_{num_seeds}_expansions_{num_expansions}_initial_network_{initial_network_id}.png',\n",
    "    bbox_inches=\"tight\")  # save the figure to file\n",
    "plt.close(fig)  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:49:59.296086Z",
     "start_time": "2024-05-06T22:49:59.092066200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "colors = [\"blue\", \"green\", \"cyan\", \"purple\", \"orange\", \"brown\", \"magenta\", ]\n",
    "# alpha = 0.5\n",
    "fig = plt.figure(figsize=(6.4, 6.4), layout=\"constrained\")\n",
    "ax = fig.add_subplot(111)\n",
    "# ax.set_title(\"Test Accuracies der Strategien in Neuronenperspektive\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Accuracy (%)\")\n",
    "ax.set_xlim((0, max_epoch))\n",
    "ax.set_ylim((0, 100))\n",
    "curr_strat_index = 0\n",
    "for i, strategy in enumerate(acc_means):  # iterates over keys which are the same for each result dict\n",
    "    if \"neurons\" in strategy:\n",
    "        ax.plot(np.arange(1, len(acc_means[strategy]) + 1), acc_means[strategy], label=strategy,\n",
    "                color=colors[curr_strat_index], alpha=0.5)  #, alpha= alpha\n",
    "        curr_strat_index += 1\n",
    "        # if alpha == 0.5:\n",
    "        #     alpha -= 0.25\n",
    "        # else:\n",
    "        #     alpha += 0.25\n",
    "ax.plot(np.arange(1, len(acc_means[\"baseline\"]) + 1), acc_means[\"baseline\"], color=\"red\", label=\"baseline\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    f'../plots/{dataset_name}/Accuracies_Neurons_One_Plot_seed_1_to_{num_seeds}_expansions_{num_expansions}_initial_network_{initial_network_id}.png',\n",
    "    bbox_inches=\"tight\")  # save the figure to file\n",
    "plt.close(fig) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:50:00.206530600Z",
     "start_time": "2024-05-06T22:49:59.989270Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "num_layers = num_params_layers_expansions_means[\"random_edges\"].shape[1]\n",
    "fig = plt.figure(figsize=(4 * 6.4, 4 * 4.8), layout=\"constrained\")  # 4 * 6.4, 3 * 4.8\n",
    "fig.suptitle('Weight number increase among the different layers and expansions', fontsize=16)\n",
    "\n",
    "for i, strategy in enumerate(acc_means, start=1):  # iterates over keys which are the same for each result dict\n",
    "    if strategy != \"baseline\":\n",
    "        ax_i = fig.add_subplot(4, 4, i)  # 3, 4, i\n",
    "        ax_i.set_title(strategy)\n",
    "        ax_i.set_xlabel(\"Layer\")\n",
    "        ax_i.set_ylabel(\"number of weights\")\n",
    "        #ax_i.set_xlim((0, max_epoch))\n",
    "        ax_i.set_ylim((0, 27580))\n",
    "        bottom = np.zeros(num_layers)\n",
    "        width = 0.5\n",
    "        for expansion in range(num_expansions + 1):\n",
    "            ax_i.bar(np.arange(1, num_layers + 1), num_params_layers_expansions_means[strategy][expansion, :], width,\n",
    "                     label=f\"expansion {expansion}\", bottom=bottom)\n",
    "            bottom += num_params_layers_expansions_means[strategy][expansion, :]\n",
    "            #print(bottom.sum())\n",
    "        ax_i.legend(loc=\"upper right\")\n",
    "    plt.legend()\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    f'../plots/{dataset_name}/Weight_number_increase_seed_1_to_{num_seeds}_expansions_{num_expansions}_initial_network_{initial_network_id}.pdf',\n",
    "    bbox_inches=\"tight\")  # save the figure to file\n",
    "plt.close(fig)  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:45:01.282171200Z",
     "start_time": "2024-05-06T22:44:58.851906Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "num_layers = num_params_layers_expansions_means[\"random_edges\"].shape[1]\n",
    "fig = plt.figure(figsize=(3 * 6.4, 1 * 4.8), layout=\"constrained\")  # 4 * 6.4, 3 * 4.8\n",
    "# fig.suptitle(f'Anzahl hinzugefügter Parameter zu jeder Schicht über alle Expansionen ({dataset_name})', fontsize=16)\n",
    "\n",
    "j=1\n",
    "for i, strategy in enumerate(acc_means, start=1):  # iterates over keys which are the same for each result dict\n",
    "    if \"initial_edges\" in strategy or \"random_edges\" in strategy or \"warmstarted_edges\" in strategy:\n",
    "        ax_i = fig.add_subplot(1, 3, j)  # 3, 4, i\n",
    "        j+=1\n",
    "        ax_i.set_title(strategy)\n",
    "        ax_i.set_xlabel(\"Layer\")\n",
    "        ax_i.set_ylabel(\"Anzahl der Parameter\")\n",
    "        #ax_i.set_xlim((0, max_epoch))\n",
    "        ax_i.set_ylim((0, 27580))\n",
    "        bottom = np.zeros(num_layers)\n",
    "        width = 0.5\n",
    "        for expansion in range(num_expansions + 1):\n",
    "            ax_i.bar(np.arange(1, num_layers + 1), num_params_layers_expansions_means[strategy][expansion, :], width,\n",
    "                     label=f\"expansion {expansion}\", bottom=bottom)\n",
    "            bottom += num_params_layers_expansions_means[strategy][expansion, :]\n",
    "            #print(bottom.sum())\n",
    "        ax_i.legend(loc=\"upper right\")\n",
    "    plt.legend()\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    f'../plots/{dataset_name}/Weight_number_increase_good_edgeStrats_seed_1_to_{num_seeds}_initial_network_{initial_network_id}.png',\n",
    "    bbox_inches=\"tight\")  # save the figure to file\n",
    "plt.close(fig)  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:55:11.524607800Z",
     "start_time": "2024-05-06T22:55:10.899739600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "num_layers = num_params_layers_expansions_means[\"random_edges\"].shape[1]\n",
    "fig = plt.figure(figsize=(1 * 6.4, 1 * 4.8), layout=\"constrained\")  # 4 * 6.4, 3 * 4.8\n",
    "# fig.suptitle(f'Anzahl hinzugefügter Parameter zu jeder Schicht über alle Expansionen ({dataset_name})', fontsize=16)\n",
    "\n",
    "j=1\n",
    "for i, strategy in enumerate(acc_means, start=1):  # iterates over keys which are the same for each result dict\n",
    "    if \"gradient_based_edges\"  in strategy:\n",
    "        ax_i = fig.add_subplot(1, 1, j)  # 3, 4, i\n",
    "        j+=1\n",
    "        ax_i.set_title(strategy)\n",
    "        ax_i.set_xlabel(\"Layer\")\n",
    "        ax_i.set_ylabel(\"Anzahl der Parameter\")\n",
    "        #ax_i.set_xlim((0, max_epoch))\n",
    "        ax_i.set_ylim((0, 27580))\n",
    "        bottom = np.zeros(num_layers)\n",
    "        width = 0.5\n",
    "        for expansion in range(num_expansions + 1):\n",
    "            ax_i.bar(np.arange(1, num_layers + 1), num_params_layers_expansions_means[strategy][expansion, :], width,\n",
    "                     label=f\"expansion {expansion}\", bottom=bottom)\n",
    "            bottom += num_params_layers_expansions_means[strategy][expansion, :]\n",
    "            #print(bottom.sum())\n",
    "        ax_i.legend(loc=\"upper right\")\n",
    "        plt.legend()\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    f'../plots/{dataset_name}/Weight_number_increase_bad_edgeStrat_seed_1_to_{num_seeds}_initial_network_{initial_network_id}.png',\n",
    "    bbox_inches=\"tight\")  # save the figure to file\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:45:06.831960900Z",
     "start_time": "2024-05-06T22:45:06.648519900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "num_layers = num_params_layers_expansions_means[\"random_edges\"].shape[1]\n",
    "fig = plt.figure(figsize=(2 * 6.4, 1 * 4.8), layout=\"constrained\")  # 4 * 6.4, 3 * 4.8\n",
    "# fig.suptitle(f'Anzahl hinzugefügter Parameter zu jeder Schicht über alle Expansionen ({dataset_name})', fontsize=16)\n",
    "\n",
    "j=1\n",
    "for i, strategy in enumerate(acc_means, start=1):  # iterates over keys which are the same for each result dict\n",
    "    if \"constant_neurons\" in strategy or \"regularized_neurons\" in strategy:\n",
    "        ax_i = fig.add_subplot(1, 2, j)  # 3, 4, i\n",
    "        j+=1\n",
    "        ax_i.set_title(strategy)\n",
    "        ax_i.set_xlabel(\"Layer\")\n",
    "        ax_i.set_ylabel(\"Anzahl der Parameter\")\n",
    "        #ax_i.set_xlim((0, max_epoch))\n",
    "        ax_i.set_ylim((0, 27580))\n",
    "        bottom = np.zeros(num_layers)\n",
    "        width = 0.5\n",
    "        for expansion in range(num_expansions + 1):\n",
    "            ax_i.bar(np.arange(1, num_layers + 1), num_params_layers_expansions_means[strategy][expansion, :], width,\n",
    "                     label=f\"expansion {expansion}\", bottom=bottom)\n",
    "            bottom += num_params_layers_expansions_means[strategy][expansion, :]\n",
    "            #print(bottom.sum())\n",
    "        ax_i.legend(loc=\"upper right\")\n",
    "        plt.legend()\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    f'../plots/{dataset_name}/Weight_number_increase_good_and_bad_neuronStrats_seed_1_to_{num_seeds}_initial_network_{initial_network_id}.png',\n",
    "    bbox_inches=\"tight\")  # save the figure to file\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:37:43.952359500Z",
     "start_time": "2024-05-06T22:37:43.535627700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Testdata and evaluating the test data (ROC-curve, precision-recall-curve, f1-score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "#load training data\n",
    "#\n",
    "# Load MINST dataset\n",
    "#\n",
    "input_path = '../MNIST/'\n",
    "training_images_filepath = join(input_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte')\n",
    "training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
    "test_images_filepath = join(input_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n",
    "test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n",
    "mnist_dataloader = mm.MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath,\n",
    "                                      test_labels_filepath)\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataloader.load_data()\n",
    "\n",
    "# convert to tensor\n",
    "X_train_mnist = torch.Tensor(np.array(x_train)).to(device)\n",
    "y_train_mnist = torch.Tensor(y_train).to(torch.long).to(device)\n",
    "X_test_mnist = torch.Tensor(np.array(x_test)).to(device)\n",
    "y_test_mnist = torch.Tensor(y_test).to(torch.long).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:37:47.310374200Z",
     "start_time": "2024-05-06T22:37:45.588178300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# Create datasets for training & validation, download if necessary\n",
    "training_set_fashion_mnist = torchvision.datasets.FashionMNIST('../Fashion_MNIST', train=True,\n",
    "                                                               transform=transforms.ToTensor(), download=True)\n",
    "test_set_fashion_mnist = torchvision.datasets.FashionMNIST('../Fashion_MNIST', train=False,\n",
    "                                                           transform=transforms.ToTensor(),\n",
    "                                                           download=True)\n",
    "\n",
    "X_train_fashion_mnist = training_set_fashion_mnist.data.to(device).to(torch.float32)\n",
    "y_train_fashion_mnist = training_set_fashion_mnist.targets.to(device).to(torch.long)\n",
    "\n",
    "X_test_fashion_mnist = test_set_fashion_mnist.data.to(device).to(torch.float32)\n",
    "y_test_fashion_mnist = test_set_fashion_mnist.targets.to(device).to(torch.long)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:37:48.011155200Z",
     "start_time": "2024-05-06T22:37:47.903672500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "label_binarizer_mnist = LabelBinarizer().fit(y_train_mnist.cpu().numpy())\n",
    "y_onehot_test_mnist = label_binarizer_mnist.transform(y_test_mnist.cpu().numpy())\n",
    "\n",
    "label_binarizer_fashion_mnist = LabelBinarizer().fit(y_train_fashion_mnist.cpu().numpy())\n",
    "y_onehot_test_fashion_mnist = label_binarizer_fashion_mnist.transform(y_test_fashion_mnist.cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:37:48.760588300Z",
     "start_time": "2024-05-06T22:37:48.732462700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ROC-Curve"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import auc as sklearn_auc\n",
    "from sklearn.metrics import roc_curve as sklearn_roc_curve"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:37:49.834508Z",
     "start_time": "2024-05-06T22:37:49.820985500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def compute_avg_curve(curves_x, curves_y, interval=(0, 1)):  #list of defining coordinate-lists respectively\n",
    "    x_val_grid = np.linspace(interval[0], interval[1], 1001 * (interval[1] - interval[0]))\n",
    "    mean_curve = np.zeros_like(x_val_grid)\n",
    "    for i in range(len(curves_x)):\n",
    "        mean_curve += np.interp(x_val_grid, curves_x[i], curves_y[i])\n",
    "    mean_curve /= len(curves_x)\n",
    "    return x_val_grid, mean_curve"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:37:50.420067700Z",
     "start_time": "2024-05-06T22:37:50.406064500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def compute_macro_avg_roc_curve(y_onehot_test, y_scores):\n",
    "    # store the fpr, tpr, and roc_auc for all OvR-classification problems\n",
    "    fpr, tpr = list(), list()\n",
    "    eps = 1e-9\n",
    "    # is_sorted = lambda a: np.all(a[:-1] <= a[1:])\n",
    "    n_classes = y_scores.shape[1]\n",
    "    for i in range(n_classes):\n",
    "        fpr_i, tpr_i, _ = sklearn_roc_curve(y_onehot_test[:, i], y_scores[:, i])\n",
    "        fpr_i += (np.cumsum(np.ones(np.size(fpr_i))) - 1) * eps\n",
    "        fpr.append(fpr_i)\n",
    "        tpr.append(tpr_i)\n",
    "\n",
    "    fpr_grid, mean_tpr = compute_avg_curve(fpr, tpr)\n",
    "    return fpr_grid, mean_tpr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:37:50.825987300Z",
     "start_time": "2024-05-06T22:37:50.813983100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def get_score_vec(X_test, state_dict, device):\n",
    "    model = mm.ProgressiveMLP(n_layers=6, n_neurons=30).to(device)\n",
    "\n",
    "    model.load_state_dict(state_dict)  # state dict after 1st expansion\n",
    "\n",
    "    y_test_pred = model(X_test)[-1]  #unnormalized logits\n",
    "\n",
    "    # print(y_test_pred.size())\n",
    "\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    y_scores_tensor = softmax(y_test_pred)  # actual class probabilities\n",
    "\n",
    "    y_scores = y_scores_tensor.detach().cpu().numpy()\n",
    "    return y_scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:37:51.365763700Z",
     "start_time": "2024-05-06T22:37:51.363758100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "strategies_roc_dict = dict()\n",
    "for strategy in strategies_result_dict.keys():\n",
    "    if strategy != \"baseline\":\n",
    "        strategies_roc_dict[strategy] = []\n",
    "\n",
    "for strategy in strategies_roc_dict:\n",
    "    for expansion in range(num_expansions + 1):\n",
    "        tpr_list, fpr_list = [], []\n",
    "        for seed in range(num_seeds):\n",
    "            if dataset_name == fashion_mnist_name:\n",
    "                y_scores = get_score_vec(X_test_fashion_mnist,\n",
    "                                         strategies_result_dict[strategy][seed][\"weights\"][expansion], device)\n",
    "                roc_curve = compute_macro_avg_roc_curve(y_onehot_test_fashion_mnist, y_scores)  # fashion_mnist\n",
    "            else:\n",
    "                y_scores = get_score_vec(X_test_mnist, strategies_result_dict[strategy][seed][\"weights\"][expansion],\n",
    "                                         device)\n",
    "                roc_curve = compute_macro_avg_roc_curve(y_onehot_test_mnist, y_scores)  # mnist\n",
    "            fpr_list.append(roc_curve[0])\n",
    "            tpr_list.append(roc_curve[1])\n",
    "        fpr, tpr = compute_avg_curve(fpr_list, tpr_list)\n",
    "        strategies_roc_dict[strategy].append((fpr, tpr))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:37:56.503836800Z",
     "start_time": "2024-05-06T22:37:51.851508100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "display_padding = 1e-2\n",
    "for strategy in strategies_roc_dict:\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    for expansion in range(num_expansions + 1):\n",
    "        ax.plot(\n",
    "            strategies_roc_dict[strategy][expansion][0],\n",
    "            strategies_roc_dict[strategy][expansion][1],\n",
    "            label=f\"Expansion {expansion} (AUC = {sklearn_auc(strategies_roc_dict[strategy][expansion][0], strategies_roc_dict[strategy][expansion][1]):.3f})\",\n",
    "            linestyle=\"solid\",\n",
    "            linewidth=1.5,\n",
    "            alpha=0.5\n",
    "        )\n",
    "    ax.plot(\n",
    "        [0, 1],\n",
    "        [0, 1],\n",
    "        label=\"Chance level (AUC = 0.5)\",\n",
    "        color=\"black\",\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=1.5\n",
    "    )\n",
    "    ax.set(\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=f\"Macro-averaged ROC-Curves\\nfor {strategy}\",\n",
    "        xlim=(0 - display_padding, 1 + display_padding),\n",
    "        ylim=(0 - display_padding, 1 + display_padding)\n",
    "    )\n",
    "    plt.legend()\n",
    "    fig.savefig(\n",
    "        f'../plots/{dataset_name}/{strategy}_ROC_curve_seed_1_to_{num_seeds}_expansions_{num_expansions}_initial_network_{initial_network_id}.pdf',\n",
    "        bbox_inches=\"tight\")  # save the figure to file\n",
    "    plt.close(fig)  # close the figure window\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:38:00.020939100Z",
     "start_time": "2024-05-06T22:37:57.043226400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "colors = [\"blue\", \"blue\", \"green\", \"green\", \"cyan\", \"cyan\", \"purple\", \"purple\", \"orange\", \"orange\", \"brown\", \"brown\",\n",
    "          \"magenta\", \"magenta\"]\n",
    "display_padding = 1e-2\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for i, strategy in enumerate(strategies_roc_dict):\n",
    "    if \"edges\" in strategy:\n",
    "        ax.plot(\n",
    "            strategies_roc_dict[strategy][1][0],\n",
    "            strategies_roc_dict[strategy][1][1],\n",
    "            label=f\"Strategy {strategy} (AUC = {sklearn_auc(strategies_roc_dict[strategy][1][0], strategies_roc_dict[strategy][1][1]):.3f})\",\n",
    "            linestyle=\"solid\",\n",
    "            color=colors[i],\n",
    "            linewidth=1.5,\n",
    "            alpha=0.5\n",
    "        )\n",
    "ax.plot(\n",
    "    [0, 1],\n",
    "    [0, 1],\n",
    "    label=\"Chance level (AUC = 0.5)\",\n",
    "    color=\"black\",\n",
    "    linestyle=\"dashed\",\n",
    "    linewidth=1.5\n",
    ")\n",
    "ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    # title=f\"Macro-Average der ROC-Kurven der Kantenstrategien\\nnach der ersten Expansion\",\n",
    "    xlim=(0 - display_padding, 1 + display_padding),\n",
    "    ylim=(0 - display_padding, 1 + display_padding)\n",
    ")\n",
    "plt.legend()\n",
    "fig.savefig(\n",
    "    f'../plots/{dataset_name}/edge_strategies_after_exp1_ROC_curve_seed_1_to_{num_seeds}_expansions_{num_expansions}_initial_network_{initial_network_id}.png',\n",
    "    bbox_inches=\"tight\")  # save the figure to file\n",
    "plt.close(fig)  # close the figure window\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:38:01.403668500Z",
     "start_time": "2024-05-06T22:38:01.193544100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "display_padding = 1e-2\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for i, strategy in enumerate(strategies_roc_dict):\n",
    "    if \"neurons\" in strategy:\n",
    "        ax.plot(\n",
    "            strategies_roc_dict[strategy][1][0],\n",
    "            strategies_roc_dict[strategy][1][1],\n",
    "            label=f\"Strategy {strategy} (AUC = {sklearn_auc(strategies_roc_dict[strategy][1][0], strategies_roc_dict[strategy][1][1]):.3f})\",\n",
    "            linestyle=\"solid\",\n",
    "            color=colors[i],\n",
    "            linewidth=1.5,\n",
    "            alpha=0.5\n",
    "        )\n",
    "ax.plot(\n",
    "    [0, 1],\n",
    "    [0, 1],\n",
    "    label=\"Chance level (AUC = 0.5)\",\n",
    "    color=\"black\",\n",
    "    linestyle=\"dashed\",\n",
    "    linewidth=1.5\n",
    ")\n",
    "ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    # title=f\"Macro-Average der ROC-Kurven der Neuronenstrategien\\nnach der ersten Expansion\",\n",
    "    xlim=(0 - display_padding, 1 + display_padding),\n",
    "    ylim=(0 - display_padding, 1 + display_padding)\n",
    ")\n",
    "plt.legend()\n",
    "fig.savefig(\n",
    "    f'../plots/{dataset_name}/neuron_strategies_after_exp1_ROC_curve_seed_1_to_{num_seeds}_expansions_{num_expansions}_initial_network_{initial_network_id}.png',\n",
    "    bbox_inches=\"tight\")  # save the figure to file\n",
    "plt.close(fig)  # close the figure window"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T22:38:02.198280300Z",
     "start_time": "2024-05-06T22:38:02.030706600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# F1-score (harmonic mean of precision and recall)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score as sklearn_f1_score\n",
    "\n",
    "strategies_f1_score_dict = dict()\n",
    "for strategy in strategies_result_dict.keys():\n",
    "    if strategy != \"baseline\":\n",
    "        strategies_f1_score_dict[strategy] = []\n",
    "\n",
    "for strategy in strategies_f1_score_dict:\n",
    "    for expansion in range(num_expansions + 1):\n",
    "        f1_list = []\n",
    "        for seed in range(num_seeds):\n",
    "            if dataset_name == fashion_mnist_name:\n",
    "                y_true = y_test_fashion_mnist.cpu().numpy()\n",
    "                y_scores = get_score_vec(X_test_fashion_mnist,\n",
    "                                         strategies_result_dict[strategy][seed][\"weights\"][expansion], device)\n",
    "            else:\n",
    "                y_true = y_test_mnist.cpu().numpy()\n",
    "                y_scores = get_score_vec(X_test_mnist, strategies_result_dict[strategy][seed][\"weights\"][expansion],\n",
    "                                         device)\n",
    "            y_pred = np.argmax(y_scores, axis=1)\n",
    "            f1_list.append(sklearn_f1_score(y_true, y_pred, average=\"macro\"))\n",
    "        strategies_f1_score_dict[strategy].append((np.mean(f1_list), np.std(f1_list)))\n",
    "\n",
    "# prepare to read in as pandas dataframe\n",
    "table_numpy = np.zeros((len(strategies_f1_score_dict), num_expansions + 1)).astype(np.str_)\n",
    "for i, strategy in enumerate(strategies_f1_score_dict):\n",
    "    for expansion in range(num_expansions + 1):\n",
    "        table_numpy[\n",
    "            i, expansion] = f\"{strategies_f1_score_dict[strategy][expansion][0]:.2f} ± {strategies_f1_score_dict[strategy][expansion][1]:.2f}\"\n",
    "\n",
    "df = pd.DataFrame(table_numpy, index=strategies_f1_score_dict.keys(),\n",
    "                  columns=np.arange(num_expansions + 1)).rename_axis(index=\"Strategie\", columns=\"Erweiterung\")\n",
    "\n",
    "with open(\n",
    "        f\"../tables/{dataset_name}/F1_Score_latex_seed_1_to_{num_seeds}_expansions_{num_expansions}_initial_network_{initial_network_id}.txt\",\n",
    "        \"w\") as text_file:\n",
    "    print(df.to_latex(), file=text_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:57:13.119142900Z",
     "start_time": "2024-04-28T15:57:10.661617900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "strategies_f1_score_dict = dict()\n",
    "for strategy in strategies_result_dict.keys():\n",
    "    if strategy != \"baseline\" and \"neurons\" not in strategy:\n",
    "        strategies_f1_score_dict[strategy] = []\n",
    "\n",
    "for strategy in strategies_f1_score_dict:\n",
    "    for expansion in range(num_expansions + 1):\n",
    "        f1_list = []\n",
    "        for seed in range(num_seeds):\n",
    "            if dataset_name == fashion_mnist_name:\n",
    "                y_true = y_test_fashion_mnist.cpu().numpy()\n",
    "                y_scores = get_score_vec(X_test_fashion_mnist,\n",
    "                                         strategies_result_dict[strategy][seed][\"weights\"][expansion], device)\n",
    "            else:\n",
    "                y_true = y_test_mnist.cpu().numpy()\n",
    "                y_scores = get_score_vec(X_test_mnist, strategies_result_dict[strategy][seed][\"weights\"][expansion],\n",
    "                                         device)\n",
    "            y_pred = np.argmax(y_scores, axis=1)\n",
    "            f1_list.append(sklearn_f1_score(y_true, y_pred, average=\"macro\"))\n",
    "        strategies_f1_score_dict[strategy].append((np.mean(f1_list), np.std(f1_list)))\n",
    "\n",
    "# prepare to read in as pandas dataframe\n",
    "table_numpy = np.zeros((len(strategies_f1_score_dict), num_expansions + 1)).astype(np.str_)\n",
    "for i, strategy in enumerate(strategies_f1_score_dict):\n",
    "    for expansion in range(num_expansions + 1):\n",
    "        table_numpy[\n",
    "            i, expansion] = f\"{strategies_f1_score_dict[strategy][expansion][0]:.2f} ± {strategies_f1_score_dict[strategy][expansion][1]:.2f}\"\n",
    "\n",
    "df = pd.DataFrame(table_numpy, index=strategies_f1_score_dict.keys(),\n",
    "                  columns=np.arange(num_expansions + 1)).rename_axis(index=\"Strategie\", columns=\"Erweiterung\")\n",
    "\n",
    "with open(\n",
    "        f\"../tables/{dataset_name}/F1_Score_edges_seed_1_to_{num_seeds}_initial_network_{initial_network_id}.txt\",\n",
    "        \"w\") as text_file:\n",
    "    print(df.to_latex(), file=text_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:57:15.045237Z",
     "start_time": "2024-04-28T15:57:13.747756800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "strategies_f1_score_dict = dict()\n",
    "for strategy in strategies_result_dict.keys():\n",
    "    if strategy != \"baseline\" and \"edges\" not in strategy:\n",
    "        strategies_f1_score_dict[strategy] = []\n",
    "\n",
    "for strategy in strategies_f1_score_dict:\n",
    "    for expansion in range(num_expansions + 1):\n",
    "        f1_list = []\n",
    "        for seed in range(num_seeds):\n",
    "            if dataset_name == fashion_mnist_name:\n",
    "                y_true = y_test_fashion_mnist.cpu().numpy()\n",
    "                y_scores = get_score_vec(X_test_fashion_mnist,\n",
    "                                         strategies_result_dict[strategy][seed][\"weights\"][expansion], device)\n",
    "            else:\n",
    "                y_true = y_test_mnist.cpu().numpy()\n",
    "                y_scores = get_score_vec(X_test_mnist, strategies_result_dict[strategy][seed][\"weights\"][expansion],\n",
    "                                         device)\n",
    "            y_pred = np.argmax(y_scores, axis=1)\n",
    "            f1_list.append(sklearn_f1_score(y_true, y_pred, average=\"macro\"))\n",
    "        strategies_f1_score_dict[strategy].append((np.mean(f1_list), np.std(f1_list)))\n",
    "\n",
    "# prepare to read in as pandas dataframe\n",
    "table_numpy = np.zeros((len(strategies_f1_score_dict), num_expansions + 1)).astype(np.str_)\n",
    "for i, strategy in enumerate(strategies_f1_score_dict):\n",
    "    for expansion in range(num_expansions + 1):\n",
    "        table_numpy[\n",
    "            i, expansion] = f\"{strategies_f1_score_dict[strategy][expansion][0]:.2f} ± {strategies_f1_score_dict[strategy][expansion][1]:.2f}\"\n",
    "\n",
    "df = pd.DataFrame(table_numpy, index=strategies_f1_score_dict.keys(),\n",
    "                  columns=np.arange(num_expansions + 1)).rename_axis(index=\"Strategie\", columns=\"Erweiterung\")\n",
    "\n",
    "with open(\n",
    "        f\"../tables/{dataset_name}/F1_Score_neurons_seed_1_to_{num_seeds}_initial_network_{initial_network_id}.txt\",\n",
    "        \"w\") as text_file:\n",
    "    print(df.to_latex(), file=text_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:57:17.738734900Z",
     "start_time": "2024-04-28T15:57:16.445202200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    n_correct = np.count_nonzero(y_true == y_pred)\n",
    "    return n_correct / y_true.size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:57:18.841809100Z",
     "start_time": "2024-04-28T15:57:18.828283300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "strategies_test_accuracy_at_expansion = dict()\n",
    "for strategy in strategies_result_dict.keys():\n",
    "    if strategy != \"baseline\":\n",
    "        strategies_test_accuracy_at_expansion[strategy] = []\n",
    "\n",
    "for strategy in strategies_test_accuracy_at_expansion:\n",
    "    for expansion in range(num_expansions + 1):\n",
    "        acc_list = []\n",
    "        for seed in range(num_seeds):\n",
    "            if dataset_name == fashion_mnist_name:\n",
    "                y_true = y_test_fashion_mnist.cpu().numpy()\n",
    "                y_scores = get_score_vec(X_test_fashion_mnist,\n",
    "                                         strategies_result_dict[strategy][seed][\"weights\"][expansion], device)\n",
    "            else:\n",
    "                y_true = y_test_mnist.cpu().numpy()\n",
    "                y_scores = get_score_vec(X_test_mnist, strategies_result_dict[strategy][seed][\"weights\"][expansion],\n",
    "                                         device)\n",
    "            y_pred = np.argmax(y_scores, axis=1)\n",
    "            acc_list.append(accuracy(y_true, y_pred))\n",
    "        strategies_test_accuracy_at_expansion[strategy].append((np.mean(acc_list), np.std(acc_list)))\n",
    "\n",
    "# prepare to read in as pandas dataframe\n",
    "table_numpy = np.zeros((len(strategies_test_accuracy_at_expansion), num_expansions + 1)).astype(np.str_)\n",
    "for i, strategy in enumerate(strategies_test_accuracy_at_expansion):\n",
    "    for expansion in range(num_expansions + 1):\n",
    "        table_numpy[\n",
    "            i, expansion] = f\"{strategies_test_accuracy_at_expansion[strategy][expansion][0]:.3f} ± {strategies_test_accuracy_at_expansion[strategy][expansion][1]:.3f}\"\n",
    "\n",
    "df = pd.DataFrame(table_numpy, index=strategies_test_accuracy_at_expansion.keys(),\n",
    "                  columns=np.arange(num_expansions + 1)).rename_axis(index=\"Strategie\", columns=\"Erweiterung\")\n",
    "\n",
    "with open(\n",
    "        f\"../tables/{dataset_name}/Accuracy_latex_seed_1_to_{num_seeds}_expansions_{num_expansions}_initial_network_{initial_network_id}.txt\",\n",
    "        \"w\") as text_file:\n",
    "    print(df.to_latex(), file=text_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:57:20.678536400Z",
     "start_time": "2024-04-28T15:57:19.444353300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "strategies_test_accuracy_at_expansion = dict()\n",
    "for strategy in strategies_result_dict.keys():\n",
    "    if strategy != \"baseline\" and \"neurons\" not in strategy:\n",
    "        strategies_test_accuracy_at_expansion[strategy] = []\n",
    "\n",
    "for strategy in strategies_test_accuracy_at_expansion:\n",
    "    for expansion in range(num_expansions + 1):\n",
    "        acc_list = []\n",
    "        for seed in range(num_seeds):\n",
    "            if dataset_name == fashion_mnist_name:\n",
    "                y_true = y_test_fashion_mnist.cpu().numpy()\n",
    "                y_scores = get_score_vec(X_test_fashion_mnist,\n",
    "                                         strategies_result_dict[strategy][seed][\"weights\"][expansion], device)\n",
    "            else:\n",
    "                y_true = y_test_mnist.cpu().numpy()\n",
    "                y_scores = get_score_vec(X_test_mnist, strategies_result_dict[strategy][seed][\"weights\"][expansion],\n",
    "                                         device)\n",
    "            y_pred = np.argmax(y_scores, axis=1)\n",
    "            acc_list.append(accuracy(y_true, y_pred))\n",
    "        strategies_test_accuracy_at_expansion[strategy].append((np.mean(acc_list), np.std(acc_list)))\n",
    "\n",
    "# prepare to read in as pandas dataframe\n",
    "table_numpy = np.zeros((len(strategies_test_accuracy_at_expansion), num_expansions + 1)).astype(np.str_)\n",
    "for i, strategy in enumerate(strategies_test_accuracy_at_expansion):\n",
    "    for expansion in range(num_expansions + 1):\n",
    "        table_numpy[\n",
    "            i, expansion] = f\"{strategies_test_accuracy_at_expansion[strategy][expansion][0]:.3f} ± {strategies_test_accuracy_at_expansion[strategy][expansion][1]:.3f}\"\n",
    "\n",
    "df = pd.DataFrame(table_numpy, index=strategies_test_accuracy_at_expansion.keys(),\n",
    "                  columns=np.arange(num_expansions + 1)).rename_axis(index=\"Strategie\", columns=\"Erweiterung\")\n",
    "\n",
    "with open(\n",
    "        f\"../tables/{dataset_name}/Accuracy_edges_seed_1_to_{num_seeds}_expansions_{num_expansions}_initial_network_{initial_network_id}.txt\",\n",
    "        \"w\") as text_file:\n",
    "    print(df.to_latex(), file=text_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:57:21.681658100Z",
     "start_time": "2024-04-28T15:57:21.161045500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "strategies_test_accuracy_at_expansion = dict()\n",
    "for strategy in strategies_result_dict.keys():\n",
    "    if strategy != \"baseline\" and \"edges\" not in strategy:\n",
    "        strategies_test_accuracy_at_expansion[strategy] = []\n",
    "\n",
    "for strategy in strategies_test_accuracy_at_expansion:\n",
    "    for expansion in range(num_expansions + 1):\n",
    "        acc_list = []\n",
    "        for seed in range(num_seeds):\n",
    "            if dataset_name == fashion_mnist_name:\n",
    "                y_true = y_test_fashion_mnist.cpu().numpy()\n",
    "                y_scores = get_score_vec(X_test_fashion_mnist,\n",
    "                                         strategies_result_dict[strategy][seed][\"weights\"][expansion], device)\n",
    "            else:\n",
    "                y_true = y_test_mnist.cpu().numpy()\n",
    "                y_scores = get_score_vec(X_test_mnist, strategies_result_dict[strategy][seed][\"weights\"][expansion],\n",
    "                                         device)\n",
    "            y_pred = np.argmax(y_scores, axis=1)\n",
    "            acc_list.append(accuracy(y_true, y_pred))\n",
    "        strategies_test_accuracy_at_expansion[strategy].append((np.mean(acc_list), np.std(acc_list)))\n",
    "\n",
    "# prepare to read in as pandas dataframe\n",
    "table_numpy = np.zeros((len(strategies_test_accuracy_at_expansion), num_expansions + 1)).astype(np.str_)\n",
    "for i, strategy in enumerate(strategies_test_accuracy_at_expansion):\n",
    "    for expansion in range(num_expansions + 1):\n",
    "        table_numpy[\n",
    "            i, expansion] = f\"{strategies_test_accuracy_at_expansion[strategy][expansion][0]:.3f} ± {strategies_test_accuracy_at_expansion[strategy][expansion][1]:.3f}\"\n",
    "\n",
    "df = pd.DataFrame(table_numpy, index=strategies_test_accuracy_at_expansion.keys(),\n",
    "                  columns=np.arange(num_expansions + 1)).rename_axis(index=\"Strategie\", columns=\"Erweiterung\")\n",
    "\n",
    "with open(\n",
    "        f\"../tables/{dataset_name}/Accuracy_neurons_seed_1_to_{num_seeds}_expansions_{num_expansions}_initial_network_{initial_network_id}.txt\",\n",
    "        \"w\") as text_file:\n",
    "    print(df.to_latex(), file=text_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:57:23.121497700Z",
     "start_time": "2024-04-28T15:57:22.624554100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AUC (area under curve)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "strategies_auc_dict = dict()\n",
    "for strategy in strategies_roc_dict:\n",
    "    strategies_auc_dict[strategy] = []\n",
    "\n",
    "for strategy in strategies_auc_dict:\n",
    "    for expansion in range(num_expansions + 1):\n",
    "        strategies_auc_dict[strategy].append(sklearn_auc(*strategies_roc_dict[strategy][expansion]))\n",
    "\n",
    "# prepare to read in as pandas dataframe\n",
    "table_numpy = np.zeros((len(strategies_auc_dict), num_expansions + 1)).astype(np.str_)\n",
    "for i, strategy in enumerate(strategies_test_accuracy_at_expansion):\n",
    "    for expansion in range(num_expansions + 1):\n",
    "        table_numpy[\n",
    "            i, expansion] = f\"{strategies_auc_dict[strategy][expansion]:.3f}\"  #  ± {strategies_test_accuracy_at_expansion[strategy][expansion][1]:.3f}\n",
    "\n",
    "df = pd.DataFrame(table_numpy, index=strategies_auc_dict.keys(), columns=np.arange(num_expansions + 1)).rename_axis(\n",
    "    index=\"Strategie\", columns=\"Erweiterung\")\n",
    "\n",
    "with open(\n",
    "        f\"../tables/{dataset_name}/AUC_latex_seed_1_to_{num_seeds}_expansions_{num_expansions}_initial_network_{initial_network_id}.txt\",\n",
    "        \"w\") as text_file:\n",
    "    print(df.to_latex(), file=text_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T13:08:53.358005900Z",
     "start_time": "2024-04-21T13:08:53.346545700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Number of layer parameters across all expansions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "num_layers = num_params_layers_expansions_means[\"random_edges\"].shape[1]\n",
    "strategies_num_params_among_layers_dict = dict()\n",
    "for strategy in strategies_result_dict.keys():\n",
    "    if strategy != \"baseline\":\n",
    "        strategies_num_params_among_layers_dict[strategy] = []\n",
    "\n",
    "for strategy in strategies_num_params_among_layers_dict:\n",
    "    strategies_num_params_among_layers_dict[strategy] = np.ravel(\n",
    "        num_params_layers_expansions_means[strategy][:2, :])  # hierarchy: expansions -> layers\n",
    "\n",
    "mux_columns = pd.MultiIndex.from_product([np.arange(2), np.arange(1, num_layers + 1)],\n",
    "                                         names=[\"Expansion\", \"Layer\"])\n",
    "\n",
    "# prepare to read in as pandas dataframe\n",
    "table_numpy = np.zeros((len(strategies_num_params_among_layers_dict), (2) * num_layers)).astype(\n",
    "    np.str_)\n",
    "for i, strategy in enumerate(strategies_num_params_among_layers_dict):\n",
    "    for j in range(table_numpy.shape[1]):\n",
    "        table_numpy[\n",
    "            i, j] = f\"{int(strategies_num_params_among_layers_dict[strategy][j]):d}\"  #  ± {strategies_test_accuracy_at_expansion[strategy][expansion][1]:.3f}\n",
    "\n",
    "df = pd.DataFrame(table_numpy, index=strategies_num_params_among_layers_dict.keys(), columns=mux_columns).rename_axis(\n",
    "    index=\"Strategie\")\n",
    "\n",
    "with open(\n",
    "        f\"../tables/{dataset_name}/Params_added_latex_seed_1_to_{num_seeds}_expansions_{num_expansions}_initial_network_{initial_network_id}.txt\",\n",
    "        \"w\") as text_file:\n",
    "    print(df.to_latex(), file=text_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:57:27.519245800Z",
     "start_time": "2024-04-28T15:57:27.492080500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "num_layers = num_params_layers_expansions_means[\"random_edges\"].shape[1]\n",
    "strategies_num_params_among_layers_dict = dict()\n",
    "for strategy in strategies_result_dict.keys():\n",
    "    if strategy != \"baseline\" and \"neurons\" not in strategy:\n",
    "        strategies_num_params_among_layers_dict[strategy] = []\n",
    "\n",
    "for strategy in strategies_num_params_among_layers_dict:\n",
    "    strategies_num_params_among_layers_dict[strategy] = np.ravel(\n",
    "        num_params_layers_expansions_means[strategy][:2, :])  # hierarchy: expansions -> layers\n",
    "\n",
    "mux_columns = pd.MultiIndex.from_product([np.arange(2), np.arange(1, num_layers + 1)],\n",
    "                                         names=[\"Expansion\", \"Layer\"])\n",
    "\n",
    "# prepare to read in as pandas dataframe\n",
    "table_numpy = np.zeros((len(strategies_num_params_among_layers_dict), (2) * num_layers)).astype(\n",
    "    np.str_)\n",
    "for i, strategy in enumerate(strategies_num_params_among_layers_dict):\n",
    "    for j in range(table_numpy.shape[1]):\n",
    "        table_numpy[\n",
    "            i, j] = f\"{int(strategies_num_params_among_layers_dict[strategy][j]):d}\"  #  ± {strategies_test_accuracy_at_expansion[strategy][expansion][1]:.3f}\n",
    "\n",
    "df = pd.DataFrame(table_numpy, index=strategies_num_params_among_layers_dict.keys(), columns=mux_columns).rename_axis(\n",
    "    index=\"Strategie\")\n",
    "\n",
    "with open(\n",
    "        f\"../tables/{dataset_name}/Params_added_edges_seed_1_to_{num_seeds}_initial_network_{initial_network_id}.txt\",\n",
    "        \"w\") as text_file:\n",
    "    print(df.to_latex(), file=text_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:57:29.773462100Z",
     "start_time": "2024-04-28T15:57:29.743289800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "num_layers = num_params_layers_expansions_means[\"random_edges\"].shape[1]\n",
    "strategies_num_params_among_layers_dict = dict()\n",
    "for strategy in strategies_result_dict.keys():\n",
    "    if strategy != \"baseline\" and \"edges\" not in strategy:\n",
    "        strategies_num_params_among_layers_dict[strategy] = []\n",
    "\n",
    "for strategy in strategies_num_params_among_layers_dict:\n",
    "    strategies_num_params_among_layers_dict[strategy] = np.ravel(\n",
    "        num_params_layers_expansions_means[strategy][:2, :])  # hierarchy: expansions -> layers\n",
    "\n",
    "mux_columns = pd.MultiIndex.from_product([np.arange(2), np.arange(1, num_layers + 1)],\n",
    "                                         names=[\"Expansion\", \"Layer\"])\n",
    "\n",
    "# prepare to read in as pandas dataframe\n",
    "table_numpy = np.zeros((len(strategies_num_params_among_layers_dict), (2) * num_layers)).astype(\n",
    "    np.str_)\n",
    "for i, strategy in enumerate(strategies_num_params_among_layers_dict):\n",
    "    for j in range(table_numpy.shape[1]):\n",
    "        table_numpy[\n",
    "            i, j] = f\"{int(strategies_num_params_among_layers_dict[strategy][j]):d}\"  #  ± {strategies_test_accuracy_at_expansion[strategy][expansion][1]:.3f}\n",
    "\n",
    "df = pd.DataFrame(table_numpy, index=strategies_num_params_among_layers_dict.keys(), columns=mux_columns).rename_axis(\n",
    "    index=\"Strategie\")\n",
    "\n",
    "with open(\n",
    "        f\"../tables/{dataset_name}/Params_added_neurons_seed_1_to_{num_seeds}_initial_network_{initial_network_id}.txt\",\n",
    "        \"w\") as text_file:\n",
    "    print(df.to_latex(), file=text_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:57:30.691988200Z",
     "start_time": "2024-04-28T15:57:30.678974800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Connectivity Score (percentage of non bias weights that are connected to input and output layer) (old)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "strategies_connectivity_dict = torch.load(\n",
    "    \"../results/\" + f\"Connectivity_scores_{dataset_name}_initial_network_{initial_network_id}_num_seeds_{num_seeds}_expansions_{num_expansions}_eps_{eps}_lr_{lr}_grad_clip_{grad_clip}.pt\") #TODO"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:57:34.657153600Z",
     "start_time": "2024-04-28T15:57:34.613019700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "strategies_connectivity_dict_chosen = dict()\n",
    "for strategy in strategies_result_dict.keys():\n",
    "    if strategy != \"baseline\":\n",
    "        strategies_connectivity_dict_chosen[strategy] = strategies_connectivity_dict[strategy]\n",
    "# prepare to read in as pandas dataframe\n",
    "table_numpy = np.zeros((len(strategies_connectivity_dict_chosen), num_expansions + 1)).astype(np.str_)\n",
    "for i, strategy in enumerate(strategies_connectivity_dict_chosen):\n",
    "    for expansion in range(num_expansions + 1):\n",
    "        table_numpy[i, expansion] = f\"{strategies_connectivity_dict[strategy][expansion]:.2f}\"\n",
    "\n",
    "df = pd.DataFrame(table_numpy, index=strategies_connectivity_dict_chosen.keys(),\n",
    "                  columns=np.arange(num_expansions + 1)).rename_axis(index=\"Strategie\", columns=\"Erweiterung\")\n",
    "\n",
    "with open(\n",
    "        f\"../tables/{dataset_name}/Connectivity_score_latex_seed_1_to_{num_seeds}_expansions_{num_expansions}_initial_network_{initial_network_id}.txt\",\n",
    "        \"w\") as text_file:\n",
    "    print(df.to_latex(), file=text_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:57:36.188766200Z",
     "start_time": "2024-04-28T15:57:36.175897300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "strategies_connectivity_dict_chosen = dict()\n",
    "for strategy in strategies_result_dict.keys():\n",
    "    if strategy != \"baseline\" and \"neurons\" not in strategy:\n",
    "        strategies_connectivity_dict_chosen[strategy] = strategies_connectivity_dict[strategy]\n",
    "# prepare to read in as pandas dataframe\n",
    "table_numpy = np.zeros((len(strategies_connectivity_dict_chosen), num_expansions + 1)).astype(np.str_)\n",
    "for i, strategy in enumerate(strategies_connectivity_dict_chosen):\n",
    "    for expansion in range(num_expansions + 1):\n",
    "        table_numpy[i, expansion] = f\"{strategies_connectivity_dict[strategy][expansion]:.2f}\"\n",
    "\n",
    "df = pd.DataFrame(table_numpy, index=strategies_connectivity_dict_chosen.keys(),\n",
    "                  columns=np.arange(num_expansions + 1)).rename_axis(index=\"Strategie\", columns=\"Erweiterung\")\n",
    "\n",
    "with open(\n",
    "        f\"../tables/{dataset_name}/Connectivity_score_edges_seed_1_to_{num_seeds}_initial_network_{initial_network_id}.txt\",\n",
    "        \"w\") as text_file:\n",
    "    print(df.to_latex(), file=text_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:57:36.870975900Z",
     "start_time": "2024-04-28T15:57:36.842964Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "strategies_connectivity_dict_chosen = dict()\n",
    "for strategy in strategies_result_dict.keys():\n",
    "    if strategy != \"baseline\" and \"edges\" not in strategy:\n",
    "        strategies_connectivity_dict_chosen[strategy] = strategies_connectivity_dict[strategy]\n",
    "# prepare to read in as pandas dataframe\n",
    "table_numpy = np.zeros((len(strategies_connectivity_dict_chosen), num_expansions + 1)).astype(np.str_)\n",
    "for i, strategy in enumerate(strategies_connectivity_dict_chosen):\n",
    "    for expansion in range(num_expansions + 1):\n",
    "        table_numpy[i, expansion] = f\"{strategies_connectivity_dict[strategy][expansion]:.2f}\"\n",
    "\n",
    "df = pd.DataFrame(table_numpy, index=strategies_connectivity_dict_chosen.keys(),\n",
    "                  columns=np.arange(num_expansions + 1)).rename_axis(index=\"Strategie\", columns=\"Erweiterung\")\n",
    "\n",
    "with open(\n",
    "        f\"../tables/{dataset_name}/Connectivity_score_neurons_seed_1_to_{num_seeds}_initial_network_{initial_network_id}.txt\",\n",
    "        \"w\") as text_file:\n",
    "    print(df.to_latex(), file=text_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:57:37.712617100Z",
     "start_time": "2024-04-28T15:57:37.702116600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Confusion Matrix computation (after 1st expansion)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix as sklearn_confusion_matrix\n",
    "\n",
    "strategies_confusion_matrix_at_expansion = dict()\n",
    "for strategy in strategies_result_dict.keys():\n",
    "    if strategy != \"baseline\":\n",
    "        strategies_confusion_matrix_at_expansion[strategy] = []\n",
    "\n",
    "for strategy in strategies_confusion_matrix_at_expansion:\n",
    "    for expansion in range(num_expansions + 1):\n",
    "        confusion_matrix_list = []\n",
    "        for seed in range(num_seeds):\n",
    "            if dataset_name == fashion_mnist_name:\n",
    "                y_true = y_test_fashion_mnist.cpu().numpy()\n",
    "                y_scores = get_score_vec(X_test_fashion_mnist,\n",
    "                                         strategies_result_dict[strategy][seed][\"weights\"][expansion], device)\n",
    "            else:\n",
    "                y_true = y_test_mnist.cpu().numpy()\n",
    "                y_scores = get_score_vec(X_test_mnist, strategies_result_dict[strategy][seed][\"weights\"][expansion],\n",
    "                                         device)\n",
    "            y_pred = np.argmax(y_scores, axis=1)\n",
    "            confusion_matrix_list.append(sklearn_confusion_matrix(y_true, y_pred, normalize=\"all\"))\n",
    "        strategies_confusion_matrix_at_expansion[strategy].append(np.mean(np.array(confusion_matrix_list), axis=0))  # np.round( , decimals=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T13:09:02.515485500Z",
     "start_time": "2024-04-21T13:09:01.116019500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# save as confusion matrix as heatmap\n",
    "# Class labels fashion mnist\n",
    "class_names_fashion_mnist = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "for strategy in strategies_confusion_matrix_at_expansion:\n",
    "    if dataset_name == fashion_mnist_name:\n",
    "        df_cm = pd.DataFrame(strategies_confusion_matrix_at_expansion[strategy][1], index = class_names_fashion_mnist,\n",
    "                      columns = class_names_fashion_mnist).rename_axis(index=\"Actual\", columns=\"Predicted\")\n",
    "    else:\n",
    "        df_cm = pd.DataFrame(strategies_confusion_matrix_at_expansion[strategy][1], index = [i for i in range(10)],\n",
    "                      columns = [i for i in range(10)]).rename_axis(index=\"Actual\", columns=\"Predicted\")\n",
    "    fig = plt.figure(figsize=(10, 7), layout=\"constrained\")\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    sn.heatmap(df_cm, annot=True, ax=ax)\n",
    "    fig.savefig(\n",
    "        f'../plots/{dataset_name}/{strategy}_confusion_matrix_at_1stExpansion_seed_1_to_{num_seeds}_expansions_{num_expansions}_initial_network_{initial_network_id}.pdf',\n",
    "        bbox_inches=\"tight\")  # save the figure to file\n",
    "    plt.close(fig)  # close the figure window"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T13:09:08.291351Z",
     "start_time": "2024-04-21T13:09:03.109109200Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
